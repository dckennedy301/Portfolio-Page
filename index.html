<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="icon" type="image/x-icon" href="/img/DK.ico">
<title>Dylan's Portfolio</title>
<style>
  /* General Styles */
  body {
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    background-color: #000000;
    margin: 0;
    color: #ffffff;
  }

  /* Navbar Styles */
  #navbar {
    background-color: #0edacf;
    width: 100%;
    position: fixed;
    top: 0;
    left: 0;
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 15px 30px;
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.4);
  }

  #navbar h1 {
    margin: 0;
    font-size: 24px;
    font-weight: 600;
    color: #000000;
  }

  #navbar a {
    color: #ffffff;
    text-align: center;
    padding: 14px 30px;
    font-size: 20px;
    text-decoration: none;
    transition: background-color 0.3s ease, color 0.3s ease;
  }

  #navbar a:hover {
    background-color: #0cb2b1;
    color: #000000;
  }

  /* Welcome Section Styles */
  #welcome-section {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 100px 15%;
    margin-top: 75px;
    background-color: #111111;
  }

  .welcome-text {
    max-width: 50%;
  }

  .welcome-text h1 {
    color: #0edacf;
    font-size: 36px;
    margin-bottom: 20px;
  }

  .welcome-text h2 {
    color: #ffffff;
    font-weight: 400;
    line-height: 1.6;
    font-size: 18px;
    margin-bottom: 20px;
  }

  .welcome-image {
    margin-left: 50px; 
  }

  .welcome-image img {
    width: 50%; /* Adjust image size */
    border: 5px solid #0edacf;
    border-radius: 50%;
  }

  /* Project Section Styles */
  #projects {
    padding: 50px 15%;
    background-color: #000000;
  }

  .project-container {
    display: flex;
    margin: 50px 0;
    background-color: #1c1c1c;
    align-items: center;
    border-radius: 10px;
    box-shadow: 0px 4px 20px rgba(0, 0, 0, 0.6);
    transition: transform 0.3s ease;
  }

  .project-container:hover {
    transform: scale(1.02);
  }

  .project-description {
    color: #ffffff;
    padding: 20px;
    font-size: 18px;
    width: 60%;
  }

  .project-description h3 {
    color: #0edacf;
  }

  .project-tile {
    border: none;
    background-color: #0edacf;
    text-decoration: none;
    padding: 10px 20px;
    cursor: pointer;
    font-size: 18px;
    color: black;
    transition: background 0.3s ease;
    margin-top: 10px;
    display: inline-block;
  }

  .project-tile:hover {
    background-color: #0cb2b1;
  }

  /* View Demo Button Styles */
  .view-demo-button {
    margin-left: 10px;
    background-color: #585858;
    color: white;
    padding: 10px 20px;
    border: none;
    cursor: pointer;
    font-size: 18px;
    text-decoration: none;
    transition: background-color 0.3s ease;
  }

  .view-demo-button:hover {
    background-color: #0cb2b1;
  }

  /* Ensuring all project images have the same size */
  .project-image img {
    width: 300px;  /* Set width for all images */
    height: 200px; /* Set height for all images */
    object-fit: cover; /* Ensures the images are cropped without distortion */
    display: block;
    border-radius: 25px;
  }

  /* Contact Section Styles */
  #contact-section {
    display: flex;
    justify-content: center;
    align-items: center;
    padding: 50px;
    background-color: #111111;
  }

  .contact-container {
    display: flex;
    flex-direction: column;
    align-items: center;
    background-color: #1c1c1c;
    border-radius: 10px;
    box-shadow: 0px 4px 20px rgba(0, 0, 0, 0.6);
    width: 80%;
    padding: 40px;
  }

  .contact-container h1 {
    color: #0edacf;
    margin-bottom: 30px;
  }

  .contact-container h2 a {
    color: #ffffff;
    text-decoration: none;
    font-size: 20px;
    transition: color 0.3s ease;
  }

  .contact-container h2 a:hover {
    color: #0edacf;
    text-decoration: underline;
  }

  /* Media Queries */
  @media screen and (max-width: 600px) {
    #welcome-section {
      flex-direction: column;
    }

    .welcome-text {
      text-align: center;
    }

    .welcome-image {
      margin-top: 30px;
      margin-left: 0; /* Reset margin-left on smaller screens */
    }

    .project-container {
      flex-direction: column;
    }

    .project-image {
      width: 100%;
    }

    .contact-container {
      width: 95%;
    }
  }
</style>
</head>
<body>
  <!-- Navbar -->
  <nav id="navbar">
    <h1>Dylan Kennedy Portfolio</h1>
    <a href="#contact-section">Contact</a>
  </nav>  

  <!-- Welcome Section -->
  <section id="welcome-section">
    <div class="welcome-text">
      <h1>Hey, I'm Dylan Kennedy</h1>
      <h2>
        I am a third-year student and a dedicated and ambitious individual
        currently pursuing a Bachelor of Science in Information Technology with
        a focus on Data Science and Robotics at Eduvos, expected to graduate in
        December 2024. My educational journey includes a National Senior
        Certificate from Overkruin High School, and I have further enhanced my
        technical skills by obtaining a CompTIA A+ certification in February
        2023.
      </h2>
    </div>
    <div class="welcome-image">
      <img src="img/Dylan.jpeg" alt="Dylan's Photo">
    </div>
  </section>

  <!-- Project Sections -->
  <section id="projects">
    <!-- Brain Tumor Detection Model Project -->
    <div class="project-container">
      <div class="project-description">
        <h3>Brain Tumor Detection Model</h3>
        <p>This project involves developing a deep learning model to automatically detect brain tumors using MRI images. The model is designed to classify images into four categories: glioma tumor, meningioma tumor, no tumor, and pituitary tumor.

Data Processing: The images are first prepared by resizing them and converting them into a format suitable for the model. The data is split into a training set, used to train the model, and a validation set, used to test the model's performance.

Model Architecture: A pre-trained ResNet-50, a powerful image recognition model, is used and fine-tuned for this specific task. The model has been adapted to classify brain MRI images into the four categories mentioned above.

Training: The model is trained on a dataset of labeled MRI images, where it learns to identify different types of brain tumors. During training, the model‚Äôs accuracy and loss (error) are tracked to ensure that it‚Äôs improving over time.

Evaluation: After training, the model is evaluated using new, unseen images. A confusion matrix is used to assess how well the model distinguishes between the different tumor types. This helps to identify which types of tumors are being accurately classified and which are more challenging for the model.

Goal: The ultimate goal of the project is to create a reliable, automated tool that can assist doctors in detecting brain tumors early, potentially improving patient outcomes by providing faster and more accurate diagnoses.

This project showcases how artificial intelligence can be applied in the medical field to enhance diagnostic accuracy, particularly in complex areas like tumor detection.</p>
        <a class="project-tile" href="https://github.com/dckennedy301/DataScienceProject" target="_blank">View Code</a>
      </div>
      <div class="project-image">
        <img src="img/tumour.png" alt="Brain Tumor Detection Model">
      </div>
    </div>
    
    <!-- Robotics Project  -->
    <div class="project-container">
      <div class="project-description">
        <h3>Semi Autonomous Surveillance Robot</h3>
        <p>The Semi-Autonomous Surveillance Robot project is designed to combine real-time object detection with manual and autonomous robotic control. Built using a Raspberry Pi, the robot leverages computer vision to track and follow a person while providing manual override capabilities through an Xbox controller.

The system employs TensorFlow Lite object detection to identify individuals using a live camera feed. When the robot identifies a person, it tracks their movement, adjusting its direction and speed based on the person‚Äôs position in the frame and distance from the robot. The motors driving the robot are controlled via GPIO pins, and pulse-width modulation (PWM) allows for smooth speed control.

Key features include:

Autonomous Tracking Mode: The robot can detect and follow a person, moving forward or backward depending on their distance and turning based on their location in the camera frame.
Manual Control: Using an Xbox controller, the user can manually override the robot‚Äôs movement, controlling direction and speed.
Object Detection: The robot uses the EfficientDet Lite model for person detection, with TensorFlow Lite enabling edge computing, ensuring efficient processing on the Raspberry Pi.
Robust Motor Control: The system uses dual motors to control movement, with precise turning and speed adjustment.
This project demonstrates the integration of AI-based vision with physical robotics, creating a semi-autonomous system that can switch between manual and automatic modes, making it ideal for surveillance or tracking applications.</p>
        <a class="project-tile" href="https://github.com/dckennedy301/Semi-Autonomous-Surveillance-Robot" target="_blank">View Code</a>
      </div>
      <div class="project-image">
        <img src="img/Robot.jpg" alt="Semi Autonomous Surveillance Robot">
      </div>
    </div>

    <!-- Arduino Arm Project -->
    <div class="project-container">
      <div class="project-description">
        <h3>Arduino Arm</h3>
        <p>This project involves building and programming a robotic arm controlled by a computer keyboard. The arm uses six servos to control different joints (waist, shoulder, elbow, wrist pitch, wrist rotation, and gripper). A Python program with the keyboard and pyFirmata libraries lets the user control the servos by pressing specific keys, allowing the arm to perform movements like opening/closing the gripper, rotating the base, and bending the joints. The goal is to create an easy-to-use robotic arm that demonstrates basic robotics and servo control, which could be expanded for more complex tasks.</p>
        <a class="project-tile" href="https://github.com/dckennedy301/Arduino_Arm/blob/main/arm.py" target="_blank">View Code</a>
      </div>
      <div class="project-image">
        <img src="img/ArduinoArm.jpeg" alt="Arduino Arm">
      </div>
    </div>

    <!-- Milk Price Prediction Model Project -->
    <div class="project-container">
      <div class="project-description">
        <h3>Milk Price Prediction Model</h3>
        <p>The project developed a milk price prediction model using linear regression to analyze the relationship between milk can weight (in grams) and their prices. The dataset, containing 100 entries, was loaded and divided into features (weight) and target variables (price). After splitting the data into training and test sets, a linear regression model was trained, resulting in the equation 
ùëù
(
ùëî
)
=
0.11
ùëî
+
21.71
p(g)=0.11g+21.71. This indicates that the price increases by approximately R0.11 for each additional gram.

The model's performance was evaluated using 
ùëÖ^2
  scores of about 0.91 for the training set and 0.92 for the test set, demonstrating strong predictive ability. Finally, the model predicted that a 1.5 kg (1500 g) milk can would cost approximately R187.70, showcasing the model's practical application in market pricing analysis.</p>
        <a class="project-tile" href="https://github.com/dckennedy301/Milk-Price-prediction/blob/main/Milk_price_prediction_model.ipynb" target="_blank">View Code</a>
      </div>
      <div class="project-image">
        <img src="img/LinearRegressionModel.PNG" alt="Milk Price Prediction Model">
      </div>
    </div>

    <!-- Clustering Model Project -->
    <div class="project-container">
      <div class="project-description">
        <h3>Clustering Model</h3>
        <p>The project involved creating a K-Means clustering model to analyze a two-dimensional dataset. After loading and visualizing the data with a scatter plot, the dataset was standardized using StandardScaler, and missing values were handled with SimpleImputer.

To determine the optimal number of clusters, both silhouette scores and the elbow method were employed. Silhouette scores were calculated for cluster sizes ranging from 2 to 15, revealing the best cluster configuration based on the highest score. The elbow method confirmed this finding by plotting the within-cluster sum of squares against the number of clusters, indicating three as the optimal number.

Ultimately, K-Means clustering was applied with three clusters, and the results were visualized, showcasing the project‚Äôs effectiveness in identifying patterns within the dataset.</p>
        <a class="project-tile" href="https://github.com/dckennedy301/Clustering-Model/blob/main/Clustering_Model.ipynb" target="_blank">View Code</a>
      </div>
      <div class="project-image">
        <img src="img/Clustering.png" alt="Clustering Model">
      </div>
    </div>

    <!-- Diabetes Prediction Model Project -->
    <div class="project-container">
      <div class="project-description">
        <h3>Diabetes Prediction Model</h3>
        <p>The project aimed to predict diabetes using a dataset containing 768 entries with various health metrics. After loading and inspecting the dataset, missing values were handled by filling them with the mean of the respective columns. The relevant features were selected, and the data was split into training (70%) and testing (30%) sets.

Feature scaling was performed using StandardScaler to standardize the data before training the model. The K-Nearest Neighbors (KNN) algorithm was used, and hyperparameter tuning was conducted using GridSearchCV to find the optimal number of neighbors. The best model was evaluated on the test set, producing an accuracy score of 69.70% and an F1 score of 53.33%.

A confusion matrix was visualized to assess the model's performance in classifying diabetes outcomes. The model also included a function for user input, allowing predictions based on user-provided health metrics. When tested with user input, the model predicted whether a person has diabetes or not, demonstrating its practical application.</p>
        <a class="project-tile" href="https://github.com/dckennedy301/Diabetes-Prediction-Model/blob/main/DiabetesPrediction.ipynb" target="_blank">View Code</a>
      </div>
      <div class="project-image">
        <img src="img/diabetes.png" alt="Diabetes Prediction Model">
      </div>
    </div>

    <!-- Genetic Algorithm Project -->
    <div class="project-container">
      <div class="project-description">
        <h3>Genetic Algorithm</h3>
        <p>The genetic algorithm project aims to optimize a sequence of stations based on their coordinates to minimize travel distance. It begins with a Station class that holds information about each station, including its ID and coordinates. The project calculates the Euclidean distance between stations and employs a genetic algorithm to evolve station sequences over generations. Key techniques like selection, crossover, and mutation are used to refine the sequences, with an initial population generated for evaluation. The algorithm iterates through generations, selecting the best-performing sequences for reproduction, until an optimal sequence is identified or a set number of generations is reached. The results, including the best sequence and its travel distance, are visualized, and the project also supports loading station coordinates from a CSV file for flexibility. Overall, it effectively demonstrates how evolutionary strategies can optimize travel route planning.</p>
        <a class="project-tile" href="https://github.com/dckennedy301/Genetic-algorithms/blob/main/Genetic-algorithms.ipynb" target="_blank">View Code</a>
      </div>
      <div class="project-image">
        <img src="img/GA.PNG" alt="Genetic Algorithm">
      </div>
    </div>

    <!-- Malaria Detection Model Using TensorFlow Project -->
    <div class="project-container">
      <div class="project-description">
        <h3>Malaria Detection Model Using TensorFlow</h3>
        <p>The project focuses on developing a malaria detection model using deep learning techniques. Initially, the project involved importing essential libraries and loading a dataset comprising 22,047 training images and 5,511 validation images, categorized into two classes: 'Parasitized' and 'Uninfected.' A sample of the dataset was visualized to understand the data distribution before normalizing the pixel values to enhance the model's performance.

The architecture of the model was designed with three convolutional layers, each increasing in the number of filters, complemented by max-pooling and dropout layers to reduce the risk of overfitting. A dense layer with a sigmoid activation function was implemented for binary classification tasks. The model was compiled using the Adam optimizer with a learning rate of 0.0001, employing binary cross-entropy as the loss function.

During training, which spanned 50 epochs, early stopping was utilized to prevent overfitting. Throughout the training process, the model's accuracy showed significant improvement, surpassing 90% by the 25th epoch. This project effectively illustrates the application of deep learning in classifying images of malaria-infected and uninfected cells.</p>
        <a class="project-tile" href="https://github.com/dckennedy301/Malaria_Model/blob/main/Malaria_Model.ipynb" target="_blank">View Code</a>
      </div>
      <div class="project-image">
        <img src="img/TMalariaModel.PNG" alt="Malaria Detection Model">
      </div>
    </div>
  </section>

  <!-- Contact Section -->
  <section id="contact-section">
    <div class="contact-container" id="contact">
      <h1>Here's My Contact Info</h1>
      <h2><a href="https://github.com/dckennedy301" target="_blank">GitHub Profile</a></h2>
      <h2><a href="https://www.linkedin.com/in/dylan-kennedy-4b2940251/" target="_blank">LinkedIn Profile</a></h2>
      <h2><a href="https://github.com/dckennedy301/Portfolio-Page/blob/main/CV%20of%20Mr.%20Dylan%20Kennedy.pdf" target="_blank">CV</a></h2>
    </div>
  </section>
</body>
</html>
